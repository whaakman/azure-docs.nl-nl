---
title: Apache Spark streaming-taak waarmee gegevens van een Apache Kafka cluster worden gelezen, mislukt met een NoClassDefFoundError in azure HDInsight
description: Apache Spark streaming-taak waarmee gegevens van een Apache Kafka cluster worden gelezen, mislukt met een NoClassDefFoundError in azure HDInsight
ms.service: hdinsight
ms.topic: troubleshooting
author: hrasheed-msft
ms.author: hrasheed
ms.date: 07/29/2019
ms.openlocfilehash: 986b1dd2e749a0968c744f861feb0ac0bf2376e8
ms.sourcegitcommit: 800f961318021ce920ecd423ff427e69cbe43a54
ms.translationtype: MT
ms.contentlocale: nl-NL
ms.lasthandoff: 07/31/2019
ms.locfileid: "68700481"
---
# <a name="scenario-apache-spark-streaming-job-that-reads-data-from-an-apache-kafka-cluster-fails-with-a-noclassdeffounderror-in-azure-hdinsight"></a>Scenario: Apache Spark streaming-taak waarmee gegevens van een Apache Kafka cluster worden gelezen, mislukt met een NoClassDefFoundError in azure HDInsight

In dit artikel worden probleemoplossings stappen en mogelijke oplossingen voor problemen beschreven bij het gebruik van Apache Spark-onderdelen in azure HDInsight-clusters.

## <a name="issue"></a>Probleem

Het Apache Spark cluster voert een Spark-streaming-taak uit waarmee gegevens uit een Apache Kafka cluster worden gelezen. De Spark streaming-taak mislukt als de Kafka-stroom compressie is ingeschakeld. In dit geval is de application_1525986016285_0193 van de Spark-streaming-app mislukt vanwege fout:

```
18/05/17 20:01:33 WARN YarnAllocator: Container marked as failed: container_e25_1525986016285_0193_01_000032 on host: wn87-Scaled.2ajnsmlgqdsutaqydyzfzii3le.cx.internal.cloudapp.net. Exit status: 50. Diagnostics: Exception from container-launch.
Container id: container_e25_1525986016285_0193_01_000032
Exit code: 50
Stack trace: ExitCodeException exitCode=50: 
 at org.apache.hadoop.util.Shell.runCommand(Shell.java:944)
```

## <a name="cause"></a>Oorzaak

Deze fout kan worden veroorzaakt door een versie van het `spark-streaming-kafka` jar-bestand op te geven die afwijkt van de versie van het Kafka-cluster dat u uitvoert.

Als u bijvoorbeeld een Kafka-cluster versie 0.10.1 uitvoert, resulteert de volgende opdracht in een fout:

```
spark-submit \
--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.2.0
--conf spark.executor.instances=16 \
...
~/Kafka_Spark_SQL.py <bootstrap server details>
```

## <a name="resolution"></a>Oplossing

Gebruik de opdracht Spark-Submit met de `–packages` optie en zorg ervoor dat de versie van het bestand Spark-streaming-Kafka jar hetzelfde is als de versie van het Kafka-cluster dat u uitvoert.

## <a name="next-steps"></a>Volgende stappen

Als u het probleem niet ziet of als u het probleem niet kunt oplossen, gaat u naar een van de volgende kanalen voor meer ondersteuning:

* Krijg antwoorden van Azure-experts via de [ondersteuning van Azure Community](https://azure.microsoft.com/support/community/).

* Maak verbinding [@AzureSupport](https://twitter.com/azuresupport) met-het officiële Microsoft Azure account voor het verbeteren van de gebruikers ervaring door de Azure-community te verbinden met de juiste resources: antwoorden, ondersteuning en experts.

* Als u meer hulp nodig hebt, kunt u een ondersteunings aanvraag indienen via de [Azure Portal](https://portal.azure.com/?#blade/Microsoft_Azure_Support/HelpAndSupportBlade/). Selecteer **ondersteuning** in de menu balk of open de hub **Help en ondersteuning** . Lees voor meer gedetailleerde informatie [hoe u een ondersteunings aanvraag voor Azure maakt](https://docs.microsoft.com/azure/azure-supportability/how-to-create-azure-support-request). De toegang tot abonnementen voor abonnements beheer en facturering is inbegrepen bij uw Microsoft Azure-abonnement en technische ondersteuning wordt geleverd via een van de ondersteunings [abonnementen voor Azure](https://azure.microsoft.com/support/plans/).
